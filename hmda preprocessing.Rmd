---
title: "hmda 1"
output: html_document
date: "2025-11-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
```{r}
data <- read.csv("/Users/sumantchirde/Downloads/lei_B4TYDEB6GKMZO031MB27_loan_types_1-2-3-4.csv")
head(data)
```
```{r}
# --- Load Libraries ---
library(tidyverse)
library(skimr)

# --- Basic Info ---
cat("=== DATA STRUCTURE ===\n")
cat("Rows:", nrow(data), " Columns:", ncol(data), "\n\n")
cat("Preview of data:\n")
print(head(data, 3))
cat("\n")

# --- 1. Missing Value Analysis ---
cat("=== MISSING VALUE ANALYSIS ===\n")

missing_summary <- data %>%
  summarise(across(everything(),
                   ~ sum(is.na(.)) / n() * 100)) %>%
  pivot_longer(everything(),
               names_to = "column",
               values_to = "missing_percent") %>%
  arrange(desc(missing_percent))

# Show top 10 columns with missing data
top_missing <- head(missing_summary, 10)
print(top_missing)

cat("\nSuggested Fixes for Missing Data:\n")
cat("• Drop columns with >95% missing values (likely useless)\n")
cat("• Impute numeric columns with median or mean\n")
cat("• Impute categorical columns with mode or 'Unknown'\n")
cat("\n")

# --- 2. Outlier Detection (numeric columns only) ---
cat("=== OUTLIER ANALYSIS ===\n")

numeric_cols <- data %>%
  select(where(is.numeric))

outlier_summary <- numeric_cols %>%
  gather(key = "variable", value = "value") %>%
  group_by(variable) %>%
  summarise(
    Q1 = quantile(value, 0.25, na.rm = TRUE),
    Q3 = quantile(value, 0.75, na.rm = TRUE),
    IQR = Q3 - Q1,
    Lower_Bound = Q1 - 1.5 * IQR,
    Upper_Bound = Q3 + 1.5 * IQR,
    Outlier_Count = sum(value < Lower_Bound | value > Upper_Bound, na.rm = TRUE)
  ) %>%
  arrange(desc(Outlier_Count))

# Show top 10 numeric columns with outliers
top_outliers <- head(outlier_summary, 10)
print(top_outliers)

cat("\nSuggested Fixes for Outliers:\n")
cat("• Cap values outside [Lower_Bound, Upper_Bound] range\n")
cat("• Verify if extreme values are valid (e.g., large loan_amounts)\n")
cat("• Remove clear data entry errors if identified\n")
cat("\n")

# --- 3. Inconsistency Checks ---
cat("=== INCONSISTENCY CHECKS ===\n")

# Identify character columns that should be numeric
suspect_numeric <- data %>%
  select(where(is.character)) %>%
  select(where(~ all(grepl('^[0-9\\.]+$', .x[!is.na(.x)]) | is.na(.x))))

if (ncol(suspect_numeric) > 0) {
  cat("Columns that appear numeric but are stored as text:\n")
  print(names(suspect_numeric))
} else {
  cat("No obvious numeric-text inconsistencies detected.\n")
}

cat("\nSuggested Fixes for Inconsistencies:\n")
cat("• Convert numeric-like character columns to numeric\n")
cat("• Standardize categorical labels (e.g., 'Male'/'M')\n")
cat("• Ensure consistent encoding (UTF-8) across columns\n")
cat("\n")

# --- 4. Summary Report ---
cat("=== SUMMARY REPORT ===\n")
cat("→ Total rows:", nrow(data), "\n")
cat("→ Total columns:", ncol(data), "\n")
cat("→ Columns with missing data:", sum(missing_summary$missing_percent > 0), "\n")
cat("→ Columns with potential outliers:", sum(outlier_summary$Outlier_Count > 0), "\n")

cat("\nOverall Recommendations:\n")
cat("1. Drop columns with excessive missingness (>95%).\n")
cat("2. Impute key numeric fields (income, property_value, interest_rate) with median values.\n")
cat("3. Standardize text or categorical columns with inconsistent formats.\n")
cat("4. Cap extreme numeric outliers using the IQR range.\n")
cat("5. Keep code fields (like census_tract, county_code) as categorical.\n")
cat("\n=== END OF REPORT ===\n")

```
```{r}
# install janitor if not already installed
if (!require(janitor)) {
  install.packages("janitor")
}
# --- Load Required Libraries ---
library(tidyverse)
library(janitor)

# Make a copy of your raw dataset
data_clean <- data

# --- 1. Drop Empty or Nearly-Empty Columns ---
missing_percent <- sapply(data_clean, function(x) mean(is.na(x)) * 100)
cols_to_drop <- names(missing_percent[missing_percent > 95])

cat("Dropping columns with >95% missing values:\n")
print(cols_to_drop)

data_clean <- data_clean %>% select(-all_of(cols_to_drop))


# --- 2. Fix Data Types ---
# Convert numeric-like character columns to numeric
char_to_num <- data_clean %>%
  select(where(is.character)) %>%
  select(where(~ all(grepl("^[0-9\\.]+$", .x[!is.na(.x)]) | is.na(.x)))) %>%
  names()

cat("\nConverting numeric-like character columns to numeric:\n")
print(char_to_num)

data_clean <- data_clean %>%
  mutate(across(all_of(char_to_num), as.numeric))

# Convert character categorical columns to factor
data_clean <- data_clean %>%
  mutate(across(where(is.character), as.factor))


# --- 3. Impute Missing Values ---
cat("\nImputing missing values...\n")

# Function to get mode (most frequent)
get_mode <- function(x) {
  ux <- na.omit(unique(x))
  ux[which.max(tabulate(match(x, ux)))]
}

# Numeric columns → median imputation
data_clean <- data_clean %>%
  mutate(across(where(is.numeric),
                ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))

# Factor/categorical columns → mode or "Unknown"
data_clean <- data_clean %>%
  mutate(across(where(is.factor),
                ~ fct_explicit_na(., na_level = "Unknown")))


# --- 4. Flag Outliers (IQR method, numeric only) ---
cat("\nFlagging outliers...\n")

numeric_cols <- data_clean %>% select(where(is.numeric))
outlier_flags <- numeric_cols %>%
  gather(key = "variable", value = "value") %>%
  group_by(variable) %>%
  summarise(
    Q1 = quantile(value, 0.25, na.rm = TRUE),
    Q3 = quantile(value, 0.75, na.rm = TRUE),
    IQR = Q3 - Q1,
    Lower_Bound = Q1 - 1.5 * IQR,
    Upper_Bound = Q3 + 1.5 * IQR
  )

# Create a logical matrix flagging outliers
for (v in outlier_flags$variable) {
  lb <- outlier_flags$Lower_Bound[outlier_flags$variable == v]
  ub <- outlier_flags$Upper_Bound[outlier_flags$variable == v]
  flag_col <- paste0(v, "_outlier_flag")
  data_clean[[flag_col]] <- ifelse(data_clean[[v]] < lb | data_clean[[v]] > ub, TRUE, FALSE)
}

cat("Outlier flag columns added for each numeric variable.\n")


# --- 5. Clean Column Names ---
data_clean <- janitor::clean_names(data_clean)

# --- 6. Final Summary ---
cat("\n=== CLEANING SUMMARY ===\n")
cat("Dropped columns:", length(cols_to_drop), "\n")
cat("Converted numeric-like text columns:", length(char_to_num), "\n")
cat("Outlier flag columns added:", nrow(outlier_flags), "\n")
cat("Final dataset dimensions:", dim(data_clean)[1], "rows ×", dim(data_clean)[2], "columns\n")
cat("=== END OF CLEANING ===\n")

# Optional: View summary of numeric columns after cleaning
summary(select(data_clean, where(is.numeric)))

```
```{r}
# export data clean as csv
# write.csv(data_clean, "/Users/sumantchirde/Downloads/lei_B4TYDEB6GKMZO031MB27_loan_types_1-2-3-4_cleaned.csv", row.names = FALSE)
```

```{r}
v1 <- data_clean
v1 <- v1 %>%
  mutate(
    dti_num = case_when(
      debt_to_income_ratio == "<20%"        ~ 10,
      debt_to_income_ratio == "20%-<30%"    ~ 25,
      debt_to_income_ratio == "30%-<36%"    ~ 33,
      # Exact percentage values as character (36–49)
      debt_to_income_ratio %in% as.character(36:49) ~ as.numeric(debt_to_income_ratio),
      debt_to_income_ratio == "50%-60%"     ~ 55,
      debt_to_income_ratio == ">60%"        ~ 65,   # or 70, just be consistent
    )
  )
```
```{r}
#remove the column debt_to_income_ratio with dti_num
v1 <- v1 %>% select(-debt_to_income_ratio)
#rename the column dti_num to debt_to_income_ratio
v1 <- v1 %>% rename(debt_to_income_ratio = dti_num)
#encode applicate_age
v1 <- v1 %>%
  mutate(
    applicant_age_num = case_when(
      applicant_age == "<25"      ~ 20,
      applicant_age == "25-34"     ~ 30,
      applicant_age == "35-44"     ~ 40,
      applicant_age == "45-54"     ~ 50,
      applicant_age == "55-64"     ~ 60,
      applicant_age == "65-74"   ~ 70,
      applicant_age == ">74"       ~ 80
    )
  )
```
```{r}
#remove the column applicant_age with applicant_age_num
v1 <- v1 %>% select(-applicant_age)
#rename the column applicant_age_num to applicant_age
v1 <- v1 %>% rename(applicant_age = applicant_age_num)
```
```{r}
#remove column applicant_age_above_62 from v1
v1 <- v1 %>% select(-applicant_age_above_62)

#unique number of values in categorical column:county_code
length(unique(v1$county_code))
#remove county_code column from v1
v1 <- v1 %>% select(-county_code)
```
```{r}
v1 <- v1 %>%
  mutate(
    region = case_when(
      state_code %in% c("ME","NH","VT","MA","RI","CT","NY","NJ","PA") ~ "Northeast",
      state_code %in% c("OH","IN","IL","MI","WI","MN","IA","MO","ND","SD","NE","KS") ~ "Midwest",
      state_code %in% c("DE","MD","DC","VA","WV","NC","SC","GA","FL",
                        "KY","TN","AL","MS","AR","LA","OK","TX") ~ "South",
      state_code %in% c("MT","ID","WY","CO","NM","AZ","UT","NV","WA","OR","CA","AK","HI") ~ "West",
      TRUE ~ NA_character_
    ),
    region = factor(region)
  )

#remove state_code column
v1 <- v1 %>% select(-state_code)
```
```{r}
head(v1)
```
```{r}
# drop all NA values from v1
v1 <- v1 %>% drop_na()
```
```{r}
# unique values in action taken
unique(v1$action_taken)
```
```{r}
# drop records with action_taken = 2
v1 <- v1 %>% filter(action_taken != 2)
```

```{r}
# change action_taken values: 3 -> 0 (denied)
v1 <- v1 %>%
  mutate(action_taken = case_when(
    action_taken == 1 ~ 1,  # originated
    action_taken == 3 ~ 0,  # denied
  ))
```
```{r}


```{r}
# drop all flag cols from v1
flag_cols <- grep("_outlier_flag$", colnames(v1), value = TRUE)
v1 <- v1 %>% select(-all_of(flag_cols))
```
```{r}
# v1 cols
colnames(v1)
```

```{r}
# drop these cols: "activity_year", "lei","derived_msa_md","census_tract","derived_ethnicity","derived_race" ,"derived_sex","prepayment_penalty_term","other_nonamortizing_features","co_applicant_credit_score_type","applicant_ethnicity_1","applicant_ethnicity_2","co_applicant_ethnicity_1","applicant_ethnicity_observed","co_applicant_ethnicity_observed","applicant_race_1","applicant_race_2","co_applicant_race_1","applicant_race_observed","co_applicant_race_observed","applicant_sex","co_applicant_sex","applicant_sex_observed","co_applicant_sex_observed","co_applicant_age","co_applicant_age_above_62"
cols_to_drop_v1 <- c("activity_year", "lei","derived_msa_md","census_tract","derived_ethnicity","derived_race" ,"derived_sex","prepayment_penalty_term","other_nonamortizing_features","co_applicant_credit_score_type","applicant_ethnicity_1","applicant_ethnicity_2","co_applicant_ethnicity_1","applicant_ethnicity_observed","co_applicant_ethnicity_observed","applicant_race_1","applicant_race_2","co_applicant_race_1","applicant_race_observed","co_applicant_race_observed","applicant_sex","co_applicant_sex","applicant_sex_observed","co_applicant_sex_observed","co_applicant_age","co_applicant_age_above_62")
v1 <- v1 %>% select(-all_of(cols_to_drop_v1))
```
```{r}
library(dplyr)
library(tidyr)

categorical_cols <- c(
  "region", "conforming_loan_limit",
  "derived_loan_product_type", "derived_dwelling_category", "purchaser_type", "preapproval", "loan_type",
  "loan_purpose", "lien_status", "reverse_mortgage",
  "open_end_line_of_credit", "business_or_commercial_purpose",
  "hoepa_status", "negative_amortization", "interest_only_payment",
  "balloon_payment", "construction_method", "occupancy_type",
  "manufactured_home_secured_property_type",
  "manufactured_home_land_property_interest", "total_units",
  "applicant_credit_score_type",
  "submission_of_application", "initially_payable_to_institution",
  "aus_1", "aus_2", "denial_reason_1", "denial_reason_2"
)
#find the unique number of values in each categorical column
sapply(v1[categorical_cols], function(x) length(unique(x)))
#remove categorical columns with 1 value
categorical_cols <- categorical_cols[sapply(v1[categorical_cols], function(x) length(unique(x))) > 1]
categorical_cols
#remove denial_reason_2 and denial_reason_1 from categorical_cols as it has high cardinality
categorical_cols <- setdiff(categorical_cols, c("denial_reason_1", "denial_reason_2"))
categorical_cols
```

```{r}
# number of unique values in reverse_mortgage in v1
length(unique(v1$reverse_mortgage))
```
```{r}
# drop reverse_mortgage from v1 (since only 1 value)
v1 <- v1 %>% select(-reverse_mortgage)
```
```{r}
v2 <- v1 %>%
  # make sure categorical cols are factors and add row id
  mutate(
    across(all_of(categorical_cols), as.factor),
    row_id = dplyr::row_number()
  ) %>%
  # long format for the categorical columns
  pivot_longer(
    cols = all_of(categorical_cols),
    names_to = "variable",
    values_to = "value"
  ) %>%
  # drop missing levels (optional – keep if you want NA dummies)
  filter(!is.na(value)) %>%
  # variable_level as column name
  unite("var_value", variable, value, sep = "_") %>%
  mutate(dummy = 1L) %>%
  # wide back to one row per row_id with 0/1 dummies
  pivot_wider(
    id_cols = row_id,
    names_from = var_value,
    values_from = dummy,
    values_fill = 0
  ) %>%
  # join back to original data
  right_join(v1 %>% mutate(row_id = row_number()),
             by = "row_id") %>%
  select(-row_id)
#view the structure of v1_encoded
str(v2)
#remove original categorical columns form v1
v2 <- v2 %>% select(-all_of(categorical_cols))
#export data to csv as encoded finalized data
#write_csv(v2, "v3_94variables.csv")
```
```{r}
# drop denial reason 1 and 2 from v1
v1 <- v1 %>% select(-denial_reason_1, -denial_reason_2)
# write v1 as v4_decision_tree.csv
# write_csv(v1, "v4_decision_tree.csv")
```













